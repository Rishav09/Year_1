{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.utils.data as data\n",
    "from skimage import io\n",
    "from skimage.exposure import histogram\n",
    "from skimage.morphology import binary_dilation,binary_erosion,disk,square\n",
    "from skimage.filters.rank import mean_bilateral\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu, gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = '/scratch/netra/Datasets/Drive_Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class DataLoaderSegmentation(data.Dataset):\n",
    "    def __init__(self,folder_path,transform = None):\n",
    "        super(DataLoaderSegmentation, self).__init__()\n",
    "        self.img_files = glob.glob(os.path.join(folder_path,'images','*.tif'))\n",
    "        self.mask_files = glob.glob(os.path.join(folder_path,'new_mask','*.bmp'))\n",
    "        self.alpha_files = glob.glob(os.path.join(folder_path,'alpha_mask','*gif'))\n",
    "        self.transforms = transform\n",
    "        #for img_path in img_files:\n",
    "         #   self.mask_files.append(os.path.join(folder_path,'masks',os.path.basename(img_path))\n",
    "         \n",
    "    def mask_to_class(self,mask):\n",
    "        target = torch.from_numpy(mask)\n",
    "        assert target.shape[2] ==3\n",
    "        h,w = target.shape[0],target.shape[1]\n",
    "        masks = torch.empty(h, w, dtype=torch.long)\n",
    "        colors = torch.unique(target.view(-1,target.size(2)),dim=0).numpy()\n",
    "        target = target.permute(2, 0, 1).contiguous()\n",
    "        mapping = {tuple(c): t for c, t in zip(colors.tolist(), range(len(colors)))}\n",
    "        for k in mapping:\n",
    "            idx = (target==torch.tensor(k, dtype=torch.uint8).unsqueeze(1).unsqueeze(2))\n",
    "            validx = (idx.sum(0) == 3) \n",
    "            masks[validx] = torch.tensor(mapping[k], dtype=torch.long)\n",
    "        return masks\n",
    "    \n",
    "    def elastic_transform_nearest(self,image, alpha=1000, sigma=20, spline_order=0, mode='nearest', random_state=np.random):\n",
    "        \n",
    "        image = np.array(image)\n",
    "       # assert image.ndim == 3\n",
    "        shape = image.shape[:2]\n",
    "\n",
    "        dx = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                      sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "        x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "        indices = [np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1))]\n",
    "        result = np.empty_like(image)\n",
    "        for i in range(image.shape[2]):\n",
    "            result[:, :, i] = map_coordinates(\n",
    "            image[:, :, i], indices, order=spline_order, mode=mode).reshape(shape)\n",
    "        result = Image.fromarray(result)\n",
    "        return result\n",
    "    \n",
    "    def elastic_transform_bilinear(self,image, alpha=1000, sigma=20, spline_order=1, mode='nearest', random_state=np.random):\n",
    "        \n",
    "\n",
    "        image = np.array(image)\n",
    "        #assert image.ndim == 3\n",
    "        shape = image.shape[:2]\n",
    "        dx = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "        x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "        indices = [np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1))]\n",
    "        result = np.empty_like(image)\n",
    "        for i in range(image.shape[2]):\n",
    "            result[:, :, i] = map_coordinates(\n",
    "            image[:, :, i], indices, order=spline_order, mode=mode).reshape(shape)\n",
    "        result = Image.fromarray(result)\n",
    "        return result\n",
    "    \n",
    "    def gaussian_blur(self,img_dir,mask_dir):\n",
    "        img = io.imread(img_dir,plugin = 'pil')\n",
    "        mask = io.imread(mask_dir,plugin = 'pil')\n",
    "        a = np.pad(img, ((100,100), (100,100), (0,0)), mode = \"constant\")\n",
    "        img = a\n",
    "        grayscale = rgb2gray(a)\n",
    "        global_thresh = threshold_otsu(grayscale)\n",
    "        binary_global1 = grayscale > global_thresh\n",
    "        \n",
    "        num_px_to_expand = 100\n",
    "        # process each channel (RGB) separately\n",
    "        for channel in range(a.shape[2]):\n",
    "\n",
    "    # select a single channel\n",
    "            one_channel = a[:, :, channel]\n",
    "\n",
    "    # reset binary_global for the each channel\n",
    "            binary_global = binary_global1.copy()\n",
    "\n",
    "    # erode by 5 px to get rid of unusual edges from original image\n",
    "            binary_global = binary_erosion(binary_global, disk(5))\n",
    "\n",
    "    # turn everything less than the threshold to 0\n",
    "            one_channel = one_channel * binary_global\n",
    "\n",
    "    # update pixels one at a time\n",
    "            for jj in range(num_px_to_expand):\n",
    "\n",
    "        # get 1 px ring of to update\n",
    "                px_to_update = np.logical_xor(binary_dilation(binary_global, disk(1)), \n",
    "                                      binary_global)\n",
    "\n",
    "        # update those pixels with the average of their neighborhood\n",
    "                x, y = np.where(px_to_update == 1)\n",
    "\n",
    "                for x, y in zip(x,y):\n",
    "            # make 3 x 3 px slices\n",
    "                    slices = np.s_[(x-1):(x+2), (y-1):(y+2)]\n",
    "\n",
    "            # update a single pixel\n",
    "                    one_channel[x, y] = (np.sum(one_channel[slices]*\n",
    "                                             binary_global[slices]) / \n",
    "                                       np.sum(binary_global[slices]))      \n",
    "\n",
    "\n",
    "        # update original image\n",
    "                a[:,:, channel] = one_channel\n",
    "\n",
    "        # increase binary_global by 1 px dilation\n",
    "                binary_global = binary_dilation(binary_global, disk(1))\n",
    "            \n",
    "            \n",
    "            image_blur = cv2.GaussianBlur(a,(65,65),60)\n",
    "            new_image = cv2.subtract(img,image_blur, dtype=cv2.CV_32F)\n",
    "            out = cv2.normalize(new_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "            out = out[100:684,100:665,:]\n",
    "            mask_bool = mask>0\n",
    "            crop_img = a[100:684,100:665,:]\n",
    "            gray = rgb2gray(crop_img)\n",
    "            global_thresh = threshold_otsu(grayscale)\n",
    "            binary_global_crop = gray > global_thresh\n",
    "            px_to_update = np.logical_not(np.logical_and(binary_global_crop,mask_bool))\n",
    "            x, y = np.where(px_to_update == 1)\n",
    "            for x, y in zip(x,y):\n",
    "                out[x,y,:] = 0\n",
    "            \n",
    "            out = Image.fromarray(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def transform(self,image,mask):\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(\n",
    "        image, output_size=(512, 512))\n",
    "        image = TF.crop(image, i, j, h, w)\n",
    "        mask = TF.crop(mask, i, j, h, w)\n",
    "        \n",
    "        #image = TF.Lambda(gaussian_blur),\n",
    "       # mask = \n",
    "        #image = TF.Lambda(elastic_transform)\n",
    "        # Random horizontal flipping\n",
    "        #image = transforms.transforms.Lambda(gaussian_blur)\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "        \n",
    "        image = TF.rotate(image,90)\n",
    "        mask = TF.rotate(mask,90)\n",
    "        image = TF.rotate(image,180)\n",
    "        mask = TF.rotate(mask,180)\n",
    "        image = TF.rotate(image,270)\n",
    "        mask = TF.rotate(mask,270)\n",
    "\n",
    "        # Transform to tensor\n",
    "        #image = TF.to_tensor(image)\n",
    "#         mask = TF.to_tensor(mask)\n",
    "        return image, mask\n",
    "     \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_files[index]\n",
    "        mask_path = self.mask_files[index]\n",
    "        alpha_path = self.alpha_files[index]\n",
    "        #data = Image.open(img_path)\n",
    "        label = Image.open(mask_path)\n",
    "       # label = np.array(label)\n",
    "        data = self.gaussian_blur(img_path,alpha_path)\n",
    "        data = self.elastic_transform_bilinear(data)\n",
    "        label = self.elastic_transform_nearest(label)\n",
    "        data,label = self.transform(data,label)\n",
    "        label = np.array(label)\n",
    "        data = np.array(data)\n",
    "        #label = np.transpose(label,(2,0,1))\n",
    "        mask = self.mask_to_class(label)\n",
    "        if transforms is not None:\n",
    "             data = self.transforms(data)\n",
    "        return data,mask\n",
    "       # return data, torch.from_numpy(label).long()\n",
    "           \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "w0 = 10\n",
    "sigma = 5\n",
    "\n",
    "def make_weight_map(masks):\n",
    "    \"\"\"\n",
    "    Generate the weight maps as specified in the UNet paper\n",
    "    for a set of binary masks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    masks: array-like\n",
    "        A 3D array of shape (n_masks, image_height, image_width),\n",
    "        where each slice of the matrix along the 0th axis represents one binary mask.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        A 2D array of shape (image_height, image_width)\n",
    "    \n",
    "    \"\"\"\n",
    "    masks = masks.numpy()\n",
    "    nrows, ncols = masks.shape[1:]\n",
    "    masks = (masks > 0).astype(int)\n",
    "    distMap = np.zeros((nrows * ncols, masks.shape[0]))\n",
    "    X1, Y1 = np.meshgrid(np.arange(nrows), np.arange(ncols))\n",
    "    X1, Y1 = np.c_[X1.ravel(), Y1.ravel()].T\n",
    "    for i, mask in enumerate(masks):\n",
    "        # find the boundary of each mask,\n",
    "        # compute the distance of each pixel from this boundary\n",
    "        bounds = find_boundaries(mask, mode='inner')\n",
    "        X2, Y2 = np.nonzero(bounds)\n",
    "        xSum = (X2.reshape(-1, 1) - X1.reshape(1, -1)) ** 2\n",
    "        ySum = (Y2.reshape(-1, 1) - Y1.reshape(1, -1)) ** 2\n",
    "        distMap[:, i] = np.sqrt(xSum + ySum).min(axis=0)\n",
    "    ix = np.arange(distMap.shape[0])\n",
    "    if distMap.shape[1] == 1:\n",
    "        d1 = distMap.ravel()\n",
    "        border_loss_map = w0 * np.exp((-1 * (d1) ** 2) / (2 * (sigma ** 2)))\n",
    "    else:\n",
    "        if distMap.shape[1] == 2:\n",
    "            d1_ix, d2_ix = np.argpartition(distMap, 1, axis=1)[:, :2].T\n",
    "        else:\n",
    "            d1_ix, d2_ix = np.argpartition(distMap, 2, axis=1)[:, :2].T\n",
    "        d1 = distMap[ix, d1_ix]\n",
    "        d2 = distMap[ix, d2_ix]\n",
    "        border_loss_map = w0 * np.exp((-1 * (d1 + d2) ** 2) / (2 * (sigma ** 2)))\n",
    "    xBLoss = np.zeros((nrows, ncols))\n",
    "    xBLoss[X1, Y1] = border_loss_map\n",
    "    # class weight map\n",
    "    loss = np.zeros((nrows, ncols))\n",
    "    w_1 = 1 - masks.sum() / loss.size\n",
    "    w_0 = 1 - w_1\n",
    "    loss[masks.sum(0) == 1] = w_1\n",
    "    loss[masks.sum(0) == 0] = w_0\n",
    "    ZZ = xBLoss + loss\n",
    "    ZZ = torch.from_numpy(ZZ)\n",
    "    ZZ = ZZ.type(torch.float)\n",
    "    ZZ = ZZ.cuda()\n",
    "    return ZZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def elastic_transform_bilinear(image, alpha=1000, sigma=20, spline_order=1, mode='constant', random_state=np.random):\n",
    "    \"\"\"Elastic deformation of image as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "    \"\"\"\n",
    "#     assert image.ndim == 3\n",
    "    image = Image.open(image)\n",
    "    image = np.array(image)\n",
    " #   assert image.ndim == 3\n",
    "    shape = image.shape[:2]\n",
    "\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "    indices = [np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1))]\n",
    "    result = np.empty_like(image)\n",
    "    for i in range(image.shape[2]):\n",
    "        result[:, :, i] = map_coordinates(\n",
    "            image[:, :, i], indices, order=spline_order, mode=mode).reshape(shape)\n",
    "    result = Image.fromarray(result)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def elastic_transform_nearest(image, alpha=1000, sigma=20, spline_order=0, mode='nearest', random_state=np.random):\n",
    "    \"\"\"Elastic deformation of image as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "    \"\"\"\n",
    "#     assert image.ndim == 3\n",
    "    image = np.array(image)\n",
    "   # assert image.ndim == 3\n",
    "    shape = image.shape[:2]\n",
    "\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "    indices = [np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1))]\n",
    "    result = np.empty_like(image)\n",
    "    for i in range(image.shape[2]):\n",
    "        result[:, :, i] = map_coordinates(\n",
    "            image[:, :, i], indices, order=spline_order, mode=mode).reshape(shape)\n",
    "    result = Image.fromarray(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
